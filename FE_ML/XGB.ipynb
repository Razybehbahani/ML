{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b48b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import itertools\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "import time\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "055f75b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 29)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read all the simulation data with different properties\n",
    "df1 = pd.read_csv(\"Data/FE_constAng3_29param.csv\")\n",
    "\n",
    "df2 = pd.read_csv(\"Data/FE_Var_SizeAngle3_29param.csv\")\n",
    "\n",
    "df3 = pd.read_csv(\"Data/FE_Var_SizeConstAng3_29param.csv\")\n",
    "\n",
    "df4 = pd.read_csv(\"Data/FE_varAng3_29param.csv\")\n",
    "\n",
    "df9 = pd.read_csv(\"Data/FE_constAng3_repeat_29param.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df9], axis = 0, ignore_index = True)\n",
    "df.shape\n",
    "# df = shuffle(df)\n",
    "# df5 = pd.read_csv(\"Data/FE_constAng5_29param.csv\")\n",
    "\n",
    "# df6 = pd.read_csv(\"Data/FE_varAng5_29param.csv\")\n",
    "\n",
    "# df7 = pd.read_csv(\"Data/FE_constAng7_29param.csv\")\n",
    "\n",
    "# df8 = pd.read_csv(\"Data/FE_varAng7_29param.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8 , df9\n",
    "#                        ], axis = 0, ignore_index = True)\n",
    "\n",
    "# df = shuffle(df)\n",
    "######### or filtered data\n",
    "# df = pd.read_csv(\"Data/FE_filtered_29param.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc8ea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.FricDissipRate > 4)].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0173fcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.Safety_factor < 0.015)].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5913d139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.Tot_contactEngy > 50)].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba5f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.drop([df.loc[(df.Safety_factor < 0.015)].index[0],\n",
    "                      df.loc[(df.FricDissipRate > 4)].index[0],\n",
    "                      df.loc[(df.Tot_contactEngy > 50)].index[0]\n",
    "                      ], axis = 0)\n",
    "df = df_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a39508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Number_pieces', 'Length_ratio', 'angle1_9p', 'angle2_9', 'angle3_9p',\n",
      "       'angle4_9p', 'angle1_25p', 'angle2_25p', 'angle3_25p', 'angle4_25p',\n",
      "       'angle5_25p', 'angle6_25p', 'angle1_49p', 'angle2_49p', 'angle3_49p',\n",
      "       'angle4_49p', 'angle5_49p', 'angle6_49p', 'angle7_49p', 'angle8_49p',\n",
      "       'Safety_factor', 'Oop_deform', 'Tot_contactEngy', 'Elast_strainEngy',\n",
      "       'Edge_temp', 'Avr_frictForce', 'HeatRate', 'IntEngy', 'FricDissipRate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# ###------- normalizing data \n",
    "normalizer = MinMaxScaler()\n",
    "df_norm = normalizer.fit_transform(df)\n",
    "\n",
    "df = pd.DataFrame(df_norm, columns=df.columns )\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad929074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean3 = df.drop(df.iloc[:,6:20], axis = 'columns')\n",
    "X = df.iloc[:, 0:6]\n",
    "Y1 = df.iloc[:, 20:21]      ## Safety_factor\n",
    "Y2 = df.iloc[:, 21:22]       ## Oop_deform\n",
    "Y3 = df.iloc[:, 22:23]     ## Tot_contactEngy\n",
    "Y4 = df.iloc[:, 23:24]     ## Elast_strainEngy\n",
    "Y5 = df.iloc[:, 24:25]     ## Edge_temp\n",
    "Y6 = df.iloc[:, 25:26]     ## Avr_frictForce\n",
    "Y7 = df.iloc[:, 26:27]     ## HeatRate\n",
    "Y8 = df.iloc[:, 27:28]     ## IntEngy\n",
    "Y9 = df.iloc[:, 28:29]     ## FricDissipRate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e179dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineTree(Xtrain, Ytrain):\n",
    "    XGB_Dpt = XGBRegressor(max_depth=3,                 # Depth of each tree\n",
    "                                learning_rate=0.1,            # How much to shrink error in each subsequent training. Trade-off with no. estimators.\n",
    "                                n_estimators=100,             # How many trees to use, the more the better, but decrease learning rate if many used.\n",
    "                                verbosity=0,                  # If to show more errors or not.\n",
    "                                objective='reg:squarederror',  # Type of target variable. for classifieer use 'binary:logistic'\n",
    "                                n_jobs=4,                     # Parallel jobs to run. Set your processor number.\n",
    "                                gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)\n",
    "                                subsample=1,              # Subsample ratio. Can set lower than 1. If we want perfect boosting\n",
    "                                colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.\n",
    "                                colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest. sqrt(no.var)\n",
    "                                colsample_bynode=1,           # Subsample ratio of columns when constructing each split.\n",
    "                                scale_pos_weight=1,           # Balancing of positive and negative weights.\n",
    "                                base_score=0.5,               # Global bias. Set to average of the target rate.\n",
    "                                random_state=20210614,        # Seed\n",
    "                                missing=1                  # How are nulls encoded?\n",
    "                                )\n",
    "\n",
    "    param_grid = dict({'n_estimators': [20, 50, 100],\n",
    "                        'max_depth': [3, 5, 7],\n",
    "                        'learning_rate': [0.01, 0.1, 0.5],\n",
    "                        'subsample': [0.632, 1.],\n",
    "                        'base_score' : [0.1, 0.5, 1]\n",
    "                      })\n",
    "\n",
    "\n",
    "    # Define grid search object.\n",
    "    GridXGB = GridSearchCV(XGB_Dpt,        # Original XGB.\n",
    "                           param_grid,          # Parameter grid\n",
    "                           cv = 3,              # Number of cross validation folds.\n",
    "                           n_jobs = 4,          # Parallel jobs. -1 is \"all you have\"\n",
    "                           refit = False,       # If refit at the end with the best. We'll do it manually\n",
    "                           verbose = 1           # If to show what it is doing\n",
    "                          )\n",
    "\n",
    "    # Train grid search.\n",
    "    GridXGB.fit(Xtrain, Ytrain)\n",
    "    return GridXGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93c99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Safety_factor\n",
      " {'base_score': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.632}\n"
     ]
    }
   ],
   "source": [
    "out1 = defineTree(X, Y1)\n",
    "print('Safety_factor\\n',out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "632b50df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Oop_deform\n",
      " {'base_score': 1, 'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 20, 'subsample': 0.632}\n"
     ]
    }
   ],
   "source": [
    "out2 = defineTree(X, Y2)\n",
    "print('Oop_deform\\n',out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "289e1d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Tot_contactEngy\n",
      " {'base_score': 1, 'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 20, 'subsample': 0.632}\n"
     ]
    }
   ],
   "source": [
    "out3 = defineTree(X, Y3)\n",
    "print('Tot_contactEngy\\n',out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07cda9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Elast_strainEngy\n",
      " {'base_score': 0.5, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.632}\n"
     ]
    }
   ],
   "source": [
    "out4 = defineTree(X, Y4)\n",
    "print('Elast_strainEngy\\n',out4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f204c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Edge_temp\n",
      " {'base_score': 0.1, 'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.632}\n"
     ]
    }
   ],
   "source": [
    "out5 = defineTree(X, Y5)\n",
    "print('Edge_temp\\n',out5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1ad2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Avr_frictForce\n",
      " {'base_score': 0.5, 'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "out6 = defineTree(X, Y6)\n",
    "print('Avr_frictForce\\n',out6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90c8f752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "HeatRate\n",
      " {'base_score': 0.5, 'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "out7 = defineTree(X, Y7)\n",
    "print('HeatRate\\n',out7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3e1c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "IntEngy\n",
      " {'base_score': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.632}\n"
     ]
    }
   ],
   "source": [
    "out8 = defineTree(X, Y8)\n",
    "print('IntEngy\\n',out8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7080bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "FricDissipRate\n",
      " {'base_score': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "out9 = defineTree(X, Y9)\n",
    "print('FricDissipRate\\n',out9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b5631b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_BestParam(Xtrain, Ytrain, Xtest, Ytest, maxDepth, learningRate, nEstimators, subSamples, baseScore):\n",
    "    XGB = XGBRegressor(max_depth = maxDepth,                 # Depth of each tree\n",
    "                        learning_rate = learningRate,            # How much to shrink error in each subsequent training. Trade-off with no. estimators.\n",
    "                        n_estimators = nEstimators,             # How many trees to use, the more the better, but decrease learning rate if many used.\n",
    "                        verbosity=1,                  # If to show more errors or not.\n",
    "                        objective='reg:squarederror',  # Type of target variable. for classifieer use 'binary:logistic'\n",
    "                        n_jobs=4,                     # Parallel jobs to run. Set your processor number.\n",
    "                        gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)\n",
    "                        subsample = subSamples,              # Subsample ratio. Can set lower than 1. If we want perfect boosting\n",
    "                        colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.\n",
    "                        colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest. sqrt(no.var)\n",
    "                        colsample_bynode=1,           # Subsample ratio of columns when constructing each split.\n",
    "                        scale_pos_weight=0.5,           # Balancing of positive and negative weights.\n",
    "                        base_score = baseScore,               # Global bias. Set to average of the target rate.\n",
    "                        random_state=20210614,        # Seed\n",
    "                        missing=1                  # How are nulls encoded?\n",
    "                        )\n",
    "    XGB.fit(Xtrain, Ytrain)\n",
    "    predict = XGB.predict(Xtest)\n",
    "#     loss = mean_squared_error(Ytest, predict)\n",
    "    R2 = r2_score(Ytest, predict)\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab009c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = defineTree(Xtrain, Ytrain)\n",
    "# print(out)\n",
    "\n",
    "# baseScore = out['base_score']\n",
    "# subSamples = out['subsample']\n",
    "# nEstimators = out['n_estimators']\n",
    "# learningRate = out['learning_rate']\n",
    "# maxDepth = out['max_depth']\n",
    "\n",
    "# loss, R2 = XGB_BestParam(Xtrain, Ytrain, Xtest, Ytest, maxDepth, learningRate, nEstimators, subSamples, baseScore)\n",
    "# print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df8c11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "\n",
      " {'base_score': 0.1, 'learning_rate': 0.5, 'max_depth': 7, 'n_estimators': 20, 'subsample': 0.632}\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "\n",
      " {'base_score': 0.5, 'learning_rate': 0.5, 'max_depth': 7, 'n_estimators': 20, 'subsample': 1.0}\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "\n",
      " {'base_score': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "\n",
      " {'base_score': 0.1, 'learning_rate': 0.5, 'max_depth': 7, 'n_estimators': 20, 'subsample': 1.0}\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "\n",
      " {'base_score': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "R2s = []\n",
    "for i in range(5):\n",
    "    Xtrain, Xtest,Ytrain, Ytest,  =\\\n",
    "            train_test_split(X, Y2 ,\n",
    "            test_size = 0.02, random_state = i)\n",
    "    out = defineTree(Xtrain, Ytrain)\n",
    "    print('\\n',out)\n",
    "\n",
    "    baseScore = out['base_score']\n",
    "    subSamples = out['subsample']\n",
    "    nEstimators = out['n_estimators']\n",
    "    learningRate = out['learning_rate']\n",
    "    maxDepth = out['max_depth']\n",
    "\n",
    "    R2 = XGB_BestParam(Xtrain, Ytrain, Xtest, Ytest, maxDepth, learningRate, nEstimators, subSamples, baseScore)\n",
    "    R2s.append(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1df2f93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31403163527999967,\n",
       " 0.23232620578271568,\n",
       " 0.9423009562615317,\n",
       " 0.3358492579473742,\n",
       " -28.740166405585533]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
